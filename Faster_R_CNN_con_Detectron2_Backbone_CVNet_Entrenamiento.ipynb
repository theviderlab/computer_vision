{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvBui9WzqtVtGJdW4F/77n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theviderlab/computer_vision/blob/main/Faster_R_CNN_con_Detectron2_Backbone_CVNet_Entrenamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjv8kyAo4G3T"
      },
      "outputs": [],
      "source": [
        "# 1. Instalación de dependencias\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "from google.colab import drive\n",
        "import json\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Definición de rutas y carga de CVNet\n",
        "base_path = \"/content/drive/MyDrive/ViderLab/06 - INFORMACIÓN/Capacitación/Master/TFM/Código/\"\n",
        "cvnet_path = base_path + \"image_retrieval/backbones/\"\n",
        "sys.path.append(cvnet_path)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "from detectron2.layers import ShapeSpec\n",
        "from detectron2.modeling import BACKBONE_REGISTRY\n",
        "from detectron2.modeling.backbone import Backbone\n",
        "from detectron2.modeling.backbone.fpn import FPN, LastLevelMaxPool\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.model_zoo import get_config_file\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from cvnet.cvnet_model import CVNet_Rerank\n",
        "\n",
        "# Montaje de Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Paths para checkpoints y datos\n",
        "pretrained_weights_path = base_path + \"assets/weights/CVPR2022_CVNet_R50.pyth\"\n",
        "dataset_path = base_path + \"assets/database/open-images\"\n",
        "train_json_path = dataset_path + \"/annotations_touristic_train.json\"\n",
        "val_json_path   = os.path.join(dataset_path, \"annotations_touristic_val.json\")\n",
        "output_dir = base_path + \"/assets/weights/faster_r-cnn_cvnet_finetuned_openimages\""
      ],
      "metadata": {
        "id": "9jQRMVNE8Fan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Carga de anotaciones y definición de clases\n",
        "with open(train_json_path, 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "with open(val_json_path, 'r') as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "thing_classes = [\n",
        "    \"Building\", \"Castle\", \"Fountain\", \"Lighthouse\",\n",
        "    \"Sculpture\", \"Skyscraper\", \"Tower\"\n",
        "]"
      ],
      "metadata": {
        "id": "M837cGBQ88yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Registro de dataset en Detectron2\n",
        "DatasetCatalog.register(\"openimages_touristic_train\", lambda: train_data)\n",
        "MetadataCatalog.get(\"openimages_touristic_train\").set(thing_classes=thing_classes)\n",
        "DatasetCatalog.register(\"openimages_touristic_val\", lambda: val_data)\n",
        "MetadataCatalog.get(\"openimages_touristic_val\").set(thing_classes=thing_classes)"
      ],
      "metadata": {
        "id": "-76ozxCC9Bbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Wrapper de CVNet para FPN\n",
        "class CVNetBottomUp(Backbone):\n",
        "    def __init__(self, cvnet):\n",
        "        super().__init__()\n",
        "        self.cvnet = cvnet\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.cvnet.extract_backbone_stages(x)\n",
        "\n",
        "    def output_shape(self):\n",
        "        return {\n",
        "            \"res2\": ShapeSpec(channels=256, stride=4),\n",
        "            \"res3\": ShapeSpec(channels=512, stride=8),\n",
        "            \"res4\": ShapeSpec(channels=1024, stride=16),\n",
        "            \"res5\": ShapeSpec(channels=2048, stride=32),\n",
        "        }"
      ],
      "metadata": {
        "id": "LTrIdfCJ8NQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Registro de constructor de backbone CVNet+FPN\n",
        "@BACKBONE_REGISTRY.register()\n",
        "def build_cvnet_fpn(cfg, input_shape):\n",
        "    # Cargar CVNet_Rerank y sus pesos preentrenados\n",
        "    cvnet = CVNet_Rerank(RESNET_DEPTH=50, REDUCTION_DIM=2048)\n",
        "    checkpoint = torch.load(pretrained_weights_path, map_location='cpu')\n",
        "    state = checkpoint.get('model_state', checkpoint)\n",
        "    cvnet.load_state_dict(state, strict=False)\n",
        "    cvnet = cvnet.cuda()\n",
        "    # Congelar CVNet\n",
        "    for p in cvnet.parameters():\n",
        "        p.requires_grad = False\n",
        "    cvnet.eval()\n",
        "    # Construir FPN sobre CVNet\n",
        "    bottom_up = CVNetBottomUp(cvnet)\n",
        "    return FPN(\n",
        "        bottom_up=bottom_up,\n",
        "        in_features=cfg.MODEL.FPN.IN_FEATURES,\n",
        "        out_channels=cfg.MODEL.FPN.OUT_CHANNELS,\n",
        "        top_block=LastLevelMaxPool(),\n",
        "        fuse_type=cfg.MODEL.FPN.FUSE_TYPE,\n",
        "    )"
      ],
      "metadata": {
        "id": "RW_kM1LL_3ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Configuración base de Detectron2 y del modelo\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.RESNETS.DEPTH = 50\n",
        "cfg.MODEL.WEIGHTS = \"\"  # sin pesos COCO\n",
        "cfg.MODEL.BACKBONE.NAME = \"build_cvnet_fpn\"\n",
        "# Configuración de FPN\n",
        "cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
        "cfg.MODEL.FPN.OUT_CHANNELS = 256\n",
        "cfg.MODEL.FPN.FUSE_TYPE = \"sum\""
      ],
      "metadata": {
        "id": "oppYvSBc__qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Parámetros de entrenamiento\n",
        "# Datasets\n",
        "cfg.DATASETS.TRAIN = (\"openimages_touristic_train\",)\n",
        "cfg.DATASETS.TEST  = (\"openimages_touristic_val\",)\n",
        "\n",
        "# Número de trabajadores y directorio de salida\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "\n",
        "# Solver y LR\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "cfg.SOLVER.BASE_LR = 5e-5 * (8 / 2)\n",
        "\n",
        "# Scheduler: Warmup + MultiStepLR\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\"\n",
        "\n",
        "# Factor multiplicativo al llegar a cada step\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "# Parámetros de warm-up\n",
        "cfg.SOLVER.WARMUP_FACTOR = 0.001    # LR inicial = BASE_LR * WARMUP_FACTOR\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000      # iters de warmup\n",
        "cfg.SOLVER.WARMUP_METHOD = \"linear\" # lineal desde WARMUP_FACTOR hasta 1\n",
        "\n",
        "# Definimos iteraciones: 5 épocas ≈ 5 * (160000 / batch)\n",
        "steps_per_epoch = 160000 // batch_size()\n",
        "cfg.SOLVER.MAX_ITER = steps_per_epoch * 5  # ≈ 100k iteraciones\n",
        "# A qué iteraciones aplicar el decay\n",
        "cfg.SOLVER.STEPS = (int(cfg.SOLVER.MAX_ITER * 0.6), int(cfg.SOLVER.MAX_ITER * 0.8))\n",
        "\n",
        "# ROI Heads\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\n",
        "\n",
        "# Evaluación periódica\n",
        "eval_period = 1000  # iteraciones\n",
        "cfg.TEST.EVAL_PERIOD = eval_period\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "tLd21YulAJTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Inicializar trainer y entrenar\n",
        "trainer = DefaultTrainer(gcfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "FdW4s55q_wn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Lectura y graficado de métricas de entrenamiento\n",
        "metrics_path = os.path.join(gcfg.OUTPUT_DIR, \"metrics.json\")\n",
        "metrics = []\n",
        "with open(metrics_path) as f:\n",
        "    for line in f:\n",
        "        if line.strip() and not line.startswith(\"{\\\"iteration\\\": 0\"):\n",
        "            metrics.append(json.loads(line))\n",
        "iterations = [m[\"iteration\"] for m in metrics]\n",
        "keys = [\"total_loss\", \"loss_cls\", \"loss_box_reg\", \"loss_rpn_cls\", \"loss_rpn_loc\"]\n",
        "plt.figure(figsize=(12, 6))\n",
        "for key in keys:\n",
        "    plt.plot(iterations, [m.get(key) for m in metrics], label=key)\n",
        "plt.xlabel(\"Iteración\")\n",
        "plt.ylabel(\"Pérdida\")\n",
        "plt.title(\"Curvas de entrenamiento\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KE5obyh-k2DZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
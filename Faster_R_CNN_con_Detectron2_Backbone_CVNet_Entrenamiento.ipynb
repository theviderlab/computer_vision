{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0zshNsdHyiItgFwdhlWQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theviderlab/computer_vision/blob/main/Faster_R_CNN_con_Detectron2_Backbone_CVNet_Entrenamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sjv8kyAo4G3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27f3ef8-afc8-427f-c630-82752724b0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-s95xb5_f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-s95xb5_f\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 536dc9d527074e3b15df5f6677ffe1f4e104a4ab\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp311-cp311-linux_x86_64.whl size=6438264 sha256=e9cd41f7595f936e0e8379c0e6cdde8fe66c061d6df08584575170672cae9477\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ite09zb/wheels/17/d9/40/60db98e485aa9455d653e29d1046601ce96fe23647f60c1c5a\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=d325aa487d7683abc73e49e0d145fce68f11e8881f54f5da432a5094dbb9b90c\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4da8ac598865108665382899ae162ed2fa9e70f746788226d2ec3d26daff3a50\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-25.1.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# 1. Instalación de dependencias\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install -q wandb\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Definición de rutas y carga de CVNet\n",
        "from google.colab import drive\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Montaje de Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Cargar CVNet\n",
        "base_path = \"/content/drive/MyDrive/ViderLab/06 - INFORMACIÓN/Capacitación/Master/TFM/Código/\"\n",
        "cvnet_path = os.path.join(base_path, \"image_retrieval\", \"backbones\")\n",
        "assert os.path.isdir(cvnet_path), f\"No existe {cvnet_path}\"\n",
        "\n",
        "if cvnet_path not in sys.path:\n",
        "    sys.path.insert(0, cvnet_path)\n",
        "\n",
        "from cvnet.cvnet_model import CVNet_Rerank\n",
        "\n",
        "# Importar librerías\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from detectron2.layers import ShapeSpec\n",
        "from detectron2.modeling import BACKBONE_REGISTRY\n",
        "from detectron2.modeling.backbone import Backbone\n",
        "from detectron2.modeling.backbone.fpn import FPN, LastLevelMaxPool\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.model_zoo import get_config_file\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data import build_detection_train_loader\n",
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "from detectron2.data.transforms import (\n",
        "    RandomFlip, RandomRotation, RandomBrightness, RandomContrast,\n",
        "    RandomLighting, RandomCrop\n",
        ")\n",
        "from detectron2.utils.events import EventWriter, get_event_storage, TensorboardXWriter\n",
        "\n",
        "# Paths para checkpoints y datos\n",
        "pretrained_weights_path = base_path + \"assets/weights/CVPR2022_CVNet_R50.pyth\"\n",
        "dataset_path = base_path + \"assets/database/open-images\"\n",
        "images_path = \"/tmp/open-images\"\n",
        "train_json_path   = os.path.join(images_path, \"annotations_touristic_train.json\")\n",
        "val_json_path   = os.path.join(images_path, \"annotations_touristic_val.json\")\n",
        "output_dir = base_path + \"/assets/weights/faster_r-cnn_cvnet_finetuned_openimages\"\n",
        "dataset_name = \"rodrigodazvelasco/open-images-landmark-subset\""
      ],
      "metadata": {
        "id": "9jQRMVNE8Fan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62864e54-0050-4fc2-b3ef-b8b6347a798b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Autenticación en W&B\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "0FuFxVpp2kwi",
        "outputId": "7b8898ec-fead-40e3-b907-eb440e34fdc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtheviderlab\u001b[0m (\u001b[33mtheviderlab-viderlab\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar el dataset desde Kaggle\n",
        "src = os.path.join(base_path, \"kaggle.json\")\n",
        "dst_dir = os.path.expanduser(\"~/.kaggle\")\n",
        "dst = os.path.join(dst_dir, \"kaggle.json\")\n",
        "\n",
        "os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "!cp \"{src}\" \"{dst}\"\n",
        "!chmod 600 \"{dst}\"\n",
        "\n",
        "!kaggle datasets download -d $dataset_name -p $images_path --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLOCOs7adZA1",
        "outputId": "88bc58c6-5832-4a33-cf38-6a18f95085bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rodrigodazvelasco/open-images-landmark-subset\n",
            "License(s): unknown\n",
            "404 Client Error: Not Found for url: https://www.kaggle.com/api/v1/datasets/download/rodrigodazvelasco/open-images-landmark-subset?raw=false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Carga de anotaciones y definición de clases\n",
        "with open(train_json_path, 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "with open(val_json_path, 'r') as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "thing_classes = [\n",
        "    \"Building\", \"Castle\", \"Fountain\", \"Lighthouse\",\n",
        "    \"Sculpture\", \"Skyscraper\", \"Tower\"\n",
        "]"
      ],
      "metadata": {
        "id": "M837cGBQ88yB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Registro de dataset en Detectron2\n",
        "DatasetCatalog.register(\"openimages_touristic_train\", lambda: train_data)\n",
        "MetadataCatalog.get(\"openimages_touristic_train\").set(thing_classes=thing_classes)\n",
        "DatasetCatalog.register(\"openimages_touristic_val\", lambda: val_data)\n",
        "MetadataCatalog.get(\"openimages_touristic_val\").set(thing_classes=thing_classes)"
      ],
      "metadata": {
        "id": "-76ozxCC9Bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf5100c-924b-4f65-9fc8-f5678f29d4e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(name='openimages_touristic_val',\n",
              "          thing_classes=['Building',\n",
              "                         'Castle',\n",
              "                         'Fountain',\n",
              "                         'Lighthouse',\n",
              "                         'Sculpture',\n",
              "                         'Skyscraper',\n",
              "                         'Tower'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Wrapper de CVNet para FPN\n",
        "class CVNetBottomUp(Backbone):\n",
        "    def __init__(self, cvnet):\n",
        "        super().__init__()\n",
        "        self.cvnet = cvnet\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.cvnet.extract_backbone_stages(x)\n",
        "\n",
        "    def output_shape(self):\n",
        "        return {\n",
        "            \"res2\": ShapeSpec(channels=256, stride=4),\n",
        "            \"res3\": ShapeSpec(channels=512, stride=8),\n",
        "            \"res4\": ShapeSpec(channels=1024, stride=16),\n",
        "            \"res5\": ShapeSpec(channels=2048, stride=32),\n",
        "        }"
      ],
      "metadata": {
        "id": "LTrIdfCJ8NQF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Registro de constructor de backbone CVNet+FPN\n",
        "@BACKBONE_REGISTRY.register()\n",
        "def build_cvnet_fpn(cfg, input_shape):\n",
        "    # Cargar CVNet_Rerank y sus pesos preentrenados\n",
        "    cvnet = CVNet_Rerank(RESNET_DEPTH=50, REDUCTION_DIM=2048)\n",
        "    checkpoint = torch.load(pretrained_weights_path, map_location='cpu')\n",
        "    state = checkpoint.get('model_state', checkpoint)\n",
        "    cvnet.load_state_dict(state, strict=False)\n",
        "    cvnet = cvnet.cuda()\n",
        "    # Congelar CVNet\n",
        "    for p in cvnet.parameters():\n",
        "        p.requires_grad = False\n",
        "    cvnet.eval()\n",
        "    # Construir FPN sobre CVNet\n",
        "    bottom_up = CVNetBottomUp(cvnet)\n",
        "    return FPN(\n",
        "        bottom_up=bottom_up,\n",
        "        in_features=cfg.MODEL.FPN.IN_FEATURES,\n",
        "        out_channels=cfg.MODEL.FPN.OUT_CHANNELS,\n",
        "        top_block=LastLevelMaxPool(),\n",
        "        fuse_type=cfg.MODEL.FPN.FUSE_TYPE,\n",
        "    )"
      ],
      "metadata": {
        "id": "RW_kM1LL_3ab"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Configuración base de Detectron2 y del modelo\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.RESNETS.DEPTH = 50\n",
        "cfg.MODEL.WEIGHTS = \"\"  # sin pesos COCO\n",
        "cfg.MODEL.BACKBONE.NAME = \"build_cvnet_fpn\"\n",
        "# Configuración de FPN\n",
        "cfg.MODEL.FPN.IN_FEATURES = [\"res2\", \"res3\", \"res4\", \"res5\"]\n",
        "cfg.MODEL.FPN.OUT_CHANNELS = 256\n",
        "cfg.MODEL.FPN.FUSE_TYPE = \"sum\""
      ],
      "metadata": {
        "id": "oppYvSBc__qP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Parámetros de entrenamiento\n",
        "# Datasets\n",
        "cfg.DATASETS.TRAIN = (\"openimages_touristic_train\",)\n",
        "cfg.DATASETS.TEST  = (\"openimages_touristic_val\",)\n",
        "\n",
        "# Número de trabajadores y directorio de salida\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.OUTPUT_DIR = output_dir\n",
        "\n",
        "# Solver y LR\n",
        "cfg.SOLVER.IMS_PER_BATCH = 32\n",
        "cfg.SOLVER.BASE_LR = 5e-5 * (cfg.SOLVER.IMS_PER_BATCH / 2)\n",
        "\n",
        "# Scheduler: Warmup + MultiStepLR\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\"\n",
        "\n",
        "# Factor multiplicativo al llegar a cada step\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "# Parámetros de warm-up\n",
        "cfg.SOLVER.WARMUP_FACTOR = 0.001    # LR inicial = BASE_LR * WARMUP_FACTOR\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000      # iters de warmup\n",
        "cfg.SOLVER.WARMUP_METHOD = \"linear\" # lineal desde WARMUP_FACTOR hasta 1\n",
        "\n",
        "# Definimos iteraciones: 5 épocas ≈ 5 * (160000 / batch)\n",
        "steps_per_epoch = 160000 // cfg.SOLVER.IMS_PER_BATCH\n",
        "cfg.SOLVER.MAX_ITER = steps_per_epoch * 5  # ≈ 100k iteraciones\n",
        "# A qué iteraciones aplicar el decay\n",
        "cfg.SOLVER.STEPS = (int(cfg.SOLVER.MAX_ITER * 0.6), int(cfg.SOLVER.MAX_ITER * 0.8))\n",
        "\n",
        "# ROI Heads\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\n",
        "\n",
        "# Evaluación periódica\n",
        "cfg.TEST.EVAL_PERIOD = 1000\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 5000\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "tLd21YulAJTf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Realizar augmentations\n",
        "def custom_mapper(dataset_dict):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)\n",
        "    # Sustituye el path de Drive por el local\n",
        "    dataset_dict[\"file_name\"] = dataset_dict[\"file_name\"].replace(\n",
        "        dataset_path,\n",
        "        images_path\n",
        "    )\n",
        "    print(dataset_dict[\"file_name\"]) # debug\n",
        "\n",
        "    # 1. Leer imagen y anotaciones\n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "    annos = [obj.copy() for obj in dataset_dict.pop(\"annotations\")]\n",
        "\n",
        "    # 2. Definir augmentations\n",
        "    aug_list = [\n",
        "        RandomFlip(horizontal=True, vertical=False),\n",
        "        RandomRotation(angle=[-10, 10], sample_style=\"range\"),\n",
        "        RandomBrightness(0.8, 1.2),\n",
        "        RandomContrast(0.8, 1.2),\n",
        "        RandomLighting(0.2),\n",
        "        RandomCrop(\"relative_range\", (0.8, 0.8)),\n",
        "    ]\n",
        "\n",
        "    # 3. Aplicar las transformaciones\n",
        "    aug_input = T.AugInput(image)\n",
        "    transforms = T.AugmentationList(aug_list)(aug_input)\n",
        "    image = aug_input.image\n",
        "\n",
        "    # 4. Transformar las anotaciones (bboxes)\n",
        "    annos = [\n",
        "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
        "        for obj in annos\n",
        "    ]\n",
        "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
        "\n",
        "    # 5. Empaquetar\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "    dataset_dict[\"instances\"] = instances\n",
        "    return dataset_dict"
      ],
      "metadata": {
        "id": "kWJwEDwoUzW9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Inicializar trainer y entrenar\n",
        "# — 1) Antes de crear el Trainer, inicializa tu run de W&B:\n",
        "#    - Asegúrate de estar logueado con wandb.login()\n",
        "#    - Verifica tu identidad y entidad con: !wandb whoami\n",
        "#    - Si no perteneces a \"theviderlab\", omite o cambia `entity=...` al tuyo.\n",
        "run = wandb.init(\n",
        "    project=\"fasterrcnn-cvnet\",\n",
        "    #entity=\"theviderlab\",\n",
        "    config=cfg,\n",
        ")\n",
        "\n",
        "# — 2) Define tu WandbWriter que **usa** el run ya abierto:\n",
        "class WandbWriter(EventWriter):\n",
        "    def __init__(self):\n",
        "        # Si ya hay un run abierto, lo recoge; si no, error\n",
        "        if wandb.run is None:\n",
        "            raise RuntimeError(\"Debes llamar a wandb.init() antes de crear el Trainer\")\n",
        "        self.run = wandb.run\n",
        "\n",
        "    def write(self):\n",
        "        storage = get_event_storage()\n",
        "        latest = storage.latest()\n",
        "        wandb.log({k: float(v) for k, v in latest.items()}, step=storage.iter)\n",
        "\n",
        "    def close(self):\n",
        "        # No cerramos aquí: se cerrará al final de tu script con run.finish()\n",
        "        pass\n",
        "\n",
        "# — 3) Subclasa el Trainer para sustituir TensorboardXWriter por tu WandbWriter\n",
        "class WandbTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(cfg, mapper=custom_mapper, num_workers=cfg.DATALOADER.NUM_WORKERS)\n",
        "\n",
        "    @classmethod\n",
        "    def build_writers(cls, cfg):\n",
        "        writers = super().build_writers(cfg)\n",
        "        writers = [w for w in writers if not isinstance(w, TensorboardXWriter)]\n",
        "        writers.append(WandbWriter())\n",
        "        return writers\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        from detectron2.evaluation import COCOEvaluator\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder or os.path.join(cfg.OUTPUT_DIR, \"inference\"))\n",
        "\n",
        "# — 4) Úsalo exactamente igual:\n",
        "trainer = WandbTrainer(cfg)\n",
        "trainer.build_train_loader = lambda: build_detection_train_loader(cfg, mapper=custom_mapper)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "# — 5) Finalmente, cierra el run:\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "FdW4s55q_wn6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61b9fb12-27b5-4563-93f9-1329d1f55ded"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250511_101840-6b4jyyz9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/theviderlab-viderlab/fasterrcnn-cvnet/runs/6b4jyyz9' target=\"_blank\">azure-totem-4</a></strong> to <a href='https://wandb.ai/theviderlab-viderlab/fasterrcnn-cvnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/theviderlab-viderlab/fasterrcnn-cvnet' target=\"_blank\">https://wandb.ai/theviderlab-viderlab/fasterrcnn-cvnet</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/theviderlab-viderlab/fasterrcnn-cvnet/runs/6b4jyyz9' target=\"_blank\">https://wandb.ai/theviderlab-viderlab/fasterrcnn-cvnet/runs/6b4jyyz9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/11 10:18:42 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): CVNetBottomUp(\n",
            "      (cvnet): CVNet_Rerank(\n",
            "        (encoder_q): ResNet(\n",
            "          (stem): ResStemIN(\n",
            "            (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "          )\n",
            "          (s1): ResStage(\n",
            "            (b1): ResBlock(\n",
            "              (proj): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b2): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b3): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (s2): ResStage(\n",
            "            (b1): ResBlock(\n",
            "              (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b2): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b3): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b4): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (s3): ResStage(\n",
            "            (b1): ResBlock(\n",
            "              (proj): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b2): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b3): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b4): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b5): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b6): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (s4): ResStage(\n",
            "            (b1): ResBlock(\n",
            "              (proj): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b2): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "            (b3): ResBlock(\n",
            "              (f): BottleneckTransform(\n",
            "                (a): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (a_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (a_relu): ReLU(inplace=True)\n",
            "                (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (b_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (b_relu): ReLU(inplace=True)\n",
            "                (c): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (c_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (relu): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (head): GlobalHead(\n",
            "            (pool): GeneralizedMeanPoolingP(Parameter containing:\n",
            "            tensor([1.9281], device='cuda:0'), output_size=1)\n",
            "            (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (softmax): Softmax(dim=1)\n",
            "        (conv2ds): ModuleList(\n",
            "          (0-2): 3 x Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (cv_learner): CVLearner(\n",
            "          (block1): Sequential(\n",
            "            (0): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(9, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "              (conv2): Conv2d(9, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "            )\n",
            "            (1): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (block2): Sequential(\n",
            "            (0): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "              (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            )\n",
            "            (4): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "          (block3): Sequential(\n",
            "            (0): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (4): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "            (6): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "              (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            )\n",
            "            (7): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
            "            (8): ReLU(inplace=True)\n",
            "          )\n",
            "          (block4): Sequential(\n",
            "            (0): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (4): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "            (6): CenterPivotConv4d(\n",
            "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (7): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
            "            (8): ReLU(inplace=True)\n",
            "          )\n",
            "          (mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (1): ReLU()\n",
            "            (2): Linear(in_features=128, out_features=2, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[05/11 10:18:42 d2.data.build]: Removed 0 images with no usable annotations. 159789 images left.\n",
            "[05/11 10:18:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[05/11 10:18:48 d2.data.build]: Using training sampler TrainingSampler\n",
            "[05/11 10:18:48 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[05/11 10:18:48 d2.data.common]: Serializing 159789 elements to byte tensors and concatenating them all ...\n",
            "[05/11 10:18:49 d2.data.common]: Serialized dataset takes 60.50 MiB\n",
            "[05/11 10:18:49 d2.data.build]: Making batched data loader with batch_size=32\n",
            "[05/11 10:18:49 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from  ...\n",
            "[05/11 10:18:49 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR [05/11 10:20:49 d2.engine.train_loop]: Exception during training:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/engine/train_loop.py\", line 155, in train\n",
            "    self.run_step()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/engine/defaults.py\", line 530, in run_step\n",
            "    self._trainer.run_step()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/engine/train_loop.py\", line 297, in run_step\n",
            "    data = next(self._data_loader_iter)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\", line 329, in __iter__\n",
            "    for d in self.dataset:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1480, in _next_data\n",
            "    return self._process_data(data)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1505, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 733, in reraise\n",
            "    raise exception\n",
            "OSError: Caught OSError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 33, in fetch\n",
            "    data.append(next(self.dataset_iter))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\", line 296, in __iter__\n",
            "    yield self.dataset[idx]\n",
            "          ~~~~~~~~~~~~^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\", line 125, in __getitem__\n",
            "    data = self._map_func(self._dataset[cur_idx])\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/utils/serialize.py\", line 26, in __call__\n",
            "    return self._obj(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/dataset_mapper.py\", line 154, in __call__\n",
            "    image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/detection_utils.py\", line 180, in read_image\n",
            "    with PathManager.open(file_name, \"rb\") as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/iopath/common/file_io.py\", line 1012, in open\n",
            "    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/iopath/common/file_io.py\", line 604, in _open\n",
            "    return open(  # type: ignore\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: [Errno 5] Input/output error: '/content/drive/MyDrive/ViderLab/06 - INFORMACIÓN/Capacitación/Master/TFM/Código/assets/database/open-images/images/3deaff9332d52c4e.jpg'\n",
            "\n",
            "[05/11 10:20:49 d2.engine.hooks]: Total training time: 0:02:00 (0:00:00 on hooks)\n",
            "[05/11 10:20:49 d2.utils.events]:  iter: 0       lr: N/A  max_mem: 413M\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 33, in fetch\n    data.append(next(self.dataset_iter))\n                ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\", line 296, in __iter__\n    yield self.dataset[idx]\n          ~~~~~~~~~~~~^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\", line 125, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/utils/serialize.py\", line 26, in __call__\n    return self._obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/dataset_mapper.py\", line 154, in __call__\n    image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/detection_utils.py\", line 180, in read_image\n    with PathManager.open(file_name, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/iopath/common/file_io.py\", line 1012, in open\n    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/iopath/common/file_io.py\", line 604, in _open\n    return open(  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 5] Input/output error: '/content/drive/MyDrive/ViderLab/06 - INFORMACIÓN/Capacitación/Master/TFM/Código/assets/database/open-images/images/3deaff9332d52c4e.jpg'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-124a22310fce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbuild_detection_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_mapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# — 5) Finalmente, cierra el run:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \"\"\"\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             assert hasattr(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \"\"\"\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_loader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mdata_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"width\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mbucket_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 33, in fetch\n    data.append(next(self.dataset_iter))\n                ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\", line 296, in __iter__\n    yield self.dataset[idx]\n          ~~~~~~~~~~~~^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/common.py\", line 125, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/utils/serialize.py\", line 26, in __call__\n    return self._obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/dataset_mapper.py\", line 154, in __call__\n    image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/detectron2/data/detection_utils.py\", line 180, in read_image\n    with PathManager.open(file_name, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/iopath/common/file_io.py\", line 1012, in open\n    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/iopath/common/file_io.py\", line 604, in _open\n    return open(  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 5] Input/output error: '/content/drive/MyDrive/ViderLab/06 - INFORMACIÓN/Capacitación/Master/TFM/Código/assets/database/open-images/images/3deaff9332d52c4e.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Lectura y graficado de métricas de entrenamiento\n",
        "metrics_path = os.path.join(cfg.OUTPUT_DIR, \"metrics.json\")\n",
        "metrics = []\n",
        "with open(metrics_path) as f:\n",
        "    for line in f:\n",
        "        if line.strip() and not line.startswith(\"{\\\"iteration\\\": 0\"):\n",
        "            metrics.append(json.loads(line))\n",
        "iterations = [m[\"iteration\"] for m in metrics]\n",
        "keys = [\"total_loss\", \"loss_cls\", \"loss_box_reg\", \"loss_rpn_cls\", \"loss_rpn_loc\"]\n",
        "plt.figure(figsize=(12, 6))\n",
        "for key in keys:\n",
        "    plt.plot(iterations, [m.get(key) for m in metrics], label=key)\n",
        "plt.xlabel(\"Iteración\")\n",
        "plt.ylabel(\"Pérdida\")\n",
        "plt.title(\"Curvas de entrenamiento\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KE5obyh-k2DZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}